#!/usr/bin/python3
import argparse
import os

import awsupload
import common


def run() -> None:
    args = parse_args()

    local_artifact_root = args.local_artifact_root
    backup_directory = args.backup_directory
    dry_mode = args.dry

    for project in os.listdir(local_artifact_root):
        if not project.startswith('_'):
            project_dir = os.path.join(local_artifact_root, project)
            for build_config in os.listdir(project_dir):
                build_config_dir = os.path.join(project_dir, build_config)
                for build_number in os.listdir(build_config_dir):
                    build_dir = os.path.join(build_config_dir, build_number)
                    artifacts = [os.path.join(build_dir, entry) for entry in os.listdir(build_dir)
                                 if entry != '.teamcity']

                    json_exists = os.path.exists(os.path.join(build_dir, '.teamcity', 'artifacts.json'))
                    if artifacts and json_exists:
                        for artifact in artifacts:
                            mv(local_artifact_root, backup_directory, artifact, dry_mode)
                    elif artifacts and not json_exists:
                        raise Exception('Artifacts exist but no JSON file?! Did you successfully migrate this '
                                        'directory to S3? Each directory with artifacts should have a JSON file to go '
                                        'along with it, which would have been generated by the awsupload.py script. '
                                        + build_dir)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser()

    parser.add_argument('-b', '--backup-directory', default=common.DEFAULT_ARTIFACT_BACKUP_ROOT, required=True,
                        help='Local directory where old artifacts can be moved. This should be out of the way of '
                             'TeamCity\'s existing artifact root so as to ensure the S3 migration completed '
                             'successfully.')

    common.add_local_artifact_root_argument(parser)
    common.add_dry_mode_argument(parser)

    return parser.parse_args()


def write_json_files(local_dir: str, remote_dir: str, dry: bool) -> None:
    for build_number in os.listdir(local_dir):
        awsupload.write_json_file(local_dir, remote_dir, build_number, dry)


def mv(local_artifact_root: str, backup_directory: str, source: str, dry_mode: bool) -> None:
    relative_source = source[len(local_artifact_root):]
    target = backup_directory + relative_source

    print('{0} -> {1}'.format(source, target))
    if not dry_mode:
        os.makedirs(os.path.dirname(target), exist_ok=True)
        os.rename(source, target)


if '__main__' == __name__:
    run()
